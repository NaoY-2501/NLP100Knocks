{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 第1章: 準備運動"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 00. 文字列の逆順\n",
    "\n",
    "文字列\"stressed\"の文字を逆に（末尾から先頭に向かって）並べた文字列を得よ．\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "参考:[スライス - Python入門から応用までの学習サイト](http://www.python-izm.com/contents/basis/slice.shtml)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'desserts'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 対象の文字列\n",
    "txt = 'stressed'\n",
    "\n",
    "# [::-1]で文字列の末尾から逆順に取得することができる.\n",
    "txt[::-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 01. 「パタトクカシーー」\n",
    "\n",
    "「パタトクカシーー」という文字列の1,3,5,7文字目を取り出して連結した文字列を得よ．\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'パトカー'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "txt = 'パタトクカシーー'\n",
    "\n",
    "# [始点:終点:増分]で指定した増分だけステップ数を刻んだ文字列を取得できる.\n",
    "txt[::2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 02. 「パトカー」＋「タクシー」＝「パタトクカシーー」\n",
    "\n",
    "「パトカー」＋「タクシー」の文字を先頭から交互に連結して文字列「パタトクカシーー」を得よ．\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'パタトクカシーー'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "txt1 = 'パトカー'\n",
    "txt2 = 'タクシー'\n",
    "txt = ''\n",
    "for i in range(len(txt1)):\n",
    "    txt1Sub = txt1[i:i+1]\n",
    "    txt2Sub = txt2[i:i+1]\n",
    "    txt += txt1Sub + txt2Sub\n",
    "txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 03. 円周率\n",
    "\n",
    "\n",
    "\"Now I need a drink, alcoholic of course, after the heavy lectures involving quantum mechanics.\"という文を単語に分解し，各単語の（アルファベットの）文字数を先頭から出現順に並べたリストを作成せよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 1 4 1 5 9 2 6 5 3 5 8 9 7 9 "
     ]
    }
   ],
   "source": [
    "txt = \"Now I need a drink, alcoholic of course, after the heavy lectures involving quantum mechanics.\"\n",
    "words = txt.split(' ')\n",
    "words = [word.replace(',', '').replace('.','') \n",
    "         for word in words]\n",
    "for word in words:\n",
    "    print(len(word), end=\" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 04. 元素記号\n",
    "\n",
    "\"Hi He Lied Because Boron Could Not Oxidize Fluorine. New Nations Might Also Sign Peace Security Clause. Arthur King Can.\"という文を単語に分解し，1, 5, 6, 7, 8, 9, 15, 16, 19番目の単語は先頭の1文字，それ以外の単語は先頭に2文字を取り出し，取り出した文字列から単語の位置（先頭から何番目の単語か）への連想配列（辞書型もしくはマップ型）を作成せよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 H\n",
      "2 He\n",
      "3 Li\n",
      "4 Be\n",
      "5 B\n",
      "6 C\n",
      "7 N\n",
      "8 O\n",
      "9 F\n",
      "10 Ne\n",
      "11 Na\n",
      "12 Mi\n",
      "13 Al\n",
      "14 Si\n",
      "15 P\n",
      "16 S\n",
      "17 Cl\n",
      "18 Ar\n",
      "19 K\n",
      "20 Ca\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "txt = \"Hi He Lied Because Boron Could Not Oxidize Fluorine. New Nations Might Also Sign Peace Security Clause. Arthur King Can.\"\n",
    "\n",
    "# 文を半角スペースで分割してリストに格納\n",
    "words = txt.replace('.', '').split(\" \")\n",
    "word_position_dict = defaultdict(str)\n",
    "for idx, word in enumerate(words):\n",
    "    idx += 1\n",
    "    if (idx == 1) or (5 <= idx <= 9) or (15 <= idx <= 16) or (idx == 19):\n",
    "        word_position_dict[idx] = word[0:1]\n",
    "    else:\n",
    "        word_position_dict[idx] = word[0:2]\n",
    "\n",
    "for idx, word in word_position_dict.items():\n",
    "    print(idx, word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 05. n-gram\n",
    "\n",
    "与えられたシーケンス（文字列やリストなど）からn-gramを作る関数を作成せよ．この関数を用い，\"I am an NLPer\"という文から単語bi-gram，文字bi-gramを得よ．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**n-gram**とは\n",
    "\n",
    "文章などで隣り合うn個を指す。\n",
    "\n",
    "* 単語n-gram\n",
    "    * 隣り合うn個の単語\n",
    "    \n",
    "    * 単語bi-gram\n",
    "    \n",
    "        * this is a pen なら以下のようになる\n",
    "        \n",
    "            * this-is is-a a-pen\n",
    "* 文字n-gram\n",
    "    * 隣り合うn個の文字\n",
    "    \n",
    "    * 文字bi-gram\n",
    "        \n",
    "        * abcd なら以下のようになる\n",
    "        \n",
    "            * ab bc cd\n",
    "\n",
    "参考：[Negative/Positive Thinking * N-gram](http://d.hatena.ne.jp/jetbead/20110904/1315147133)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['I', 'am'], ['am', 'an'], ['an', 'NLPer']]\n",
      "['Ia', 'am', 'ma', 'an', 'nN', 'NL', 'LP', 'Pe', 'er']\n"
     ]
    }
   ],
   "source": [
    "def get_word_n_gram(seq,n):\n",
    "    ''' 単語n-gramwを作る\n",
    "    params:seq,n\n",
    "           seq:シーケンス\n",
    "           n:取得するn-gram\n",
    "           e.g. bi-gramなら2. tri-gramなら3\n",
    "    '''\n",
    "    words = seq.split(\" \")\n",
    "    word_n_gram = []\n",
    "    end_pos_word = len(words) - (n-1)\n",
    "\n",
    "    for pos in range(len(words)):\n",
    "        if pos == end_pos_word:\n",
    "            break\n",
    "        else:\n",
    "            word_n_gram.append(words[pos:pos+n])\n",
    "    return word_n_gram\n",
    "\n",
    "def get_char_n_gram(seq,n):\n",
    "    ''' 文字n-gramを作る関数\n",
    "    params:seq,n\n",
    "           seq:シーケンス\n",
    "           n:取得するn-gram\n",
    "           e.g. bi-gramなら2. tri-gramなら3\n",
    "    '''\n",
    "    chars = seq.replace(\" \", \"\")\n",
    "    char_n_gram = []\n",
    "    end_pos_char = len(chars) - (n-1)\n",
    "            \n",
    "    for pos in range(len(chars)):\n",
    "        if pos == end_pos_char:\n",
    "            break\n",
    "        else:\n",
    "            char_n_gram.append(chars[pos:pos+n])\n",
    "    return char_n_gram\n",
    "\n",
    "txt = \"I am an NLPer\"\n",
    "word_n_grams = get_word_n_gram(txt,2)\n",
    "print(word_n_grams)\n",
    "char_n_grams = get_char_n_gram(txt, 2)\n",
    "print(char_n_grams)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 06.集合\n",
    "\n",
    "\"paraparaparadise\"と\"paragraph\"に含まれる文字bi-gramの集合を，それぞれ, XとYとして求め，XとYの和集合，積集合，差集合を求めよ．さらに，'se'というbi-gramがXおよびYに含まれるかどうかを調べよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "paraparaparadiseの文字bi-gram集合 {'ar', 'ad', 'ap', 'di', 'pa', 'is', 'ra', 'se'}\n",
      "paragraphの文字bi-gram集合 {'ar', 'ph', 'ap', 'pa', 'ag', 'ra', 'gr'}\n",
      "\n",
      "XとYの和集合 {'ar', 'ad', 'ph', 'ap', 'di', 'pa', 'ag', 'is', 'ra', 'se', 'gr'}\n",
      "XとYの積集合 {'ar', 'ra', 'ap', 'pa'}\n",
      "XとYの差集合 {'di', 'ad', 'se', 'is'}\n",
      "seがXに含まれるか True\n",
      "seがYに含まれるか False\n"
     ]
    }
   ],
   "source": [
    "PARADISE= \"paraparaparadise\"\n",
    "PARAGRAPH= \"paragraph\"\n",
    "\n",
    "def get_char_bigram(txt):\n",
    "    bi_grams = []\n",
    "    for pos in range(len(txt)-1):\n",
    "        bi_gram = txt[pos]+txt[pos+1]\n",
    "        bi_grams.append(bi_gram)\n",
    "    return bi_grams\n",
    "\n",
    "'''\n",
    "集合(set))は重複する要素のない要素の集まり\n",
    "'''\n",
    "# PARADISEの文字bi-gram集合\n",
    "X = set(get_char_bigram(PARADISE))\n",
    "# paragraphの文字bi-gram集合\n",
    "Y = set(get_char_bigram(PARAGRAPH))\n",
    "print(\"paraparaparadiseの文字bi-gram集合\",X)\n",
    "print(\"paragraphの文字bi-gram集合\",Y)\n",
    "print()\n",
    "print(\"XとYの和集合\", X.union(Y))\n",
    "print(\"XとYの積集合\", X.intersection(Y))\n",
    "print(\"XとYの差集合\", X.difference(Y))\n",
    "print(\"seがXに含まれるか\", \"se\" in X)\n",
    "print(\"seがYに含まれるか\", \"se\" in Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 07.テンプレートによる文生成\n",
    "引数x, y, zを受け取り「x時のyはz」という文字列を返す関数を実装せよ．さらに，x=12, y=\"気温\", z=22.4として，実行結果を確認せよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12時の気温は22.4\n"
     ]
    }
   ],
   "source": [
    "def template(x,y,z):\n",
    "    mapping={\"x\":x,\"y\":y,\"z\":z}\n",
    "    print(\"{x}時の{y}は{z}\".format_map(mapping))\n",
    "    \n",
    "template(12, \"気温\", 22.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 08.暗号文\n",
    "与えられた文字列の各文字を，以下の仕様で変換する関数cipherを実装せよ．\n",
    "\n",
    "* 英小文字ならば(219 - 文字コード)の文字に置換\n",
    "* その他の文字はそのまま出力\n",
    "\n",
    "この関数を用い，英語のメッセージを暗号化・復号化せよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "平文 zen of python\n",
      "暗号化後 avm lu kbgslm\n",
      "復号化後 zen of python\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "ord(c)でUnicodeコードポイントを取得できる\n",
    "chr(i)でUnicodeコードポイントに対応した文字を取得できる\n",
    "'''\n",
    "def cipher(txt):\n",
    "    eng_lower_min=ord(\"a\")\n",
    "    eng_lower_max=ord(\"z\")\n",
    "    # 暗号化\n",
    "    encrypted = \"\"\n",
    "    for char in txt:\n",
    "        code_point = ord(char)\n",
    "        if code_point >= eng_lower_min and code_point <= eng_lower_max:\n",
    "            encrypted += (chr(219-code_point))\n",
    "        else:\n",
    "            encrypted += (char)\n",
    "    return encrypted\n",
    "\n",
    "txt = \"zen of python\"\n",
    "print(\"平文\", txt)\n",
    "encrypted = cipher(txt)\n",
    "print(\"暗号化後\", encrypted)\n",
    "decrypted = cipher(encrypted)\n",
    "print(\"復号化後\", decrypted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 09.Typoglycemia\n",
    "スペースで区切られた単語列に対して，各単語の先頭と末尾の文字は残し，それ以外の文字の順序をランダムに並び替えるプログラムを作成せよ．ただし，長さが４以下の単語は並び替えないこととする．適当な英語の文（例えば\"I couldn't believe that I could actually understand what I was reading : the phenomenal power of the human mind .\"）を与え，その実行結果を確認せよ．\n",
    "\n",
    "例文:\"I couldn't believe that I could actually understand what I was reading : the phenomenal power of the human mind .\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I cNonet bNonee that I cNoned aNoney uNoned what I was rNoneg : the pNonel pNoner of the hNonen mind . \n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Typoglycemia:単語の先頭と末尾が合っていれば、間が並び替えられていても読めてしまう現象\n",
    "'''\n",
    "import random\n",
    "\n",
    "def typoglycemia(txt):\n",
    "    # 文章を単語のリストにする\n",
    "    words = txt.split(\" \")\n",
    "    \n",
    "    typoglycemia = \"\"\n",
    "\n",
    "    for word in words:\n",
    "        if len(word) < 5:\n",
    "            typoglycemia += word\n",
    "        else:\n",
    "            shuffle_chars = [ char for char in word[1:-1] ]\n",
    "            shuffled_word = '{init}{shuffled}{end}'.format(\n",
    "                init=word[0],\n",
    "                shuffled=random.shuffle(shuffle_chars),\n",
    "                end=word[-1:]\n",
    "            )\n",
    "            typoglycemia += shuffled_word\n",
    "        typoglycemia += \" \"\n",
    "    return typoglycemia\n",
    "\n",
    "txt = \"I couldn't believe that I could actually understand what I was reading : the phenomenal power of the human mind .\"\n",
    "print(typoglycemia(txt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
